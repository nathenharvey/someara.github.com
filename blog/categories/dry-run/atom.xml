<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dry-run | A Fistful of Servers]]></title>
  <link href="http://someara.github.com/blog/categories/dry-run/atom.xml" rel="self"/>
  <link href="http://someara.github.com/"/>
  <updated>2012-12-30T12:19:28-05:00</updated>
  <id>http://someara.github.com/</id>
  <author>
    <name><![CDATA[Sean OMeara]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Promises, Lies, and Dry-Run Mode]]></title>
    <link href="http://someara.github.com/post/2012/12/21/promises-lies-and-dryrun-mode/"/>
    <updated>2012-12-21T04:20:00-05:00</updated>
    <id>http://someara.github.com/post/2012/12/21/promises-lies-and-dryrun-mode</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>


<p>{% img right http://i.imgur.com/Ftyot.jpg 300 %}</p>

<p>"I need to know what this will do to my production system before I run
it." -- Ask a Systems Administrator why they want dry-run mode in a configuration
management tool, and this is the answer you'll get almost every single time.</p>

<p>Systems Administrators have historically been able to use dry-run as a
risk mitigation strategy before applying changes to their machines.
The idea is to test a command to determine if it is safe to run.
Unfortunately, this only works if a tool's dry-run reporting can be
trusted as accurate.</p>

<p>In this post, I'll break down how modern configuration management
tools are very different animals than the  classical tool set, and why
dry-run mode is less than completely trustworthy. I'll provide
examples of dry-run saying one thing, and real-run doing another. The
takeaway should be that dry-run, while useful for development, should
never be used alone in place of proper testing.</p>

<h2> make -n </h2>


<p>{% img left http://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Ford_assembly_line<em>-</em>1913.jpg/566px-Ford_assembly_line<em>-</em>1913.jpg 300 %}</p>

<p>Many tools in a sysadmin's belt have a dry-run mode. Common
utilities like make, rsync, rpm, and apt all have it.  Many databases
will let you simulate updates, and most disk utilities can show you
changes before making them.</p>

<p>"People have been doing this for years! It should be easy to get a
list of what actions a tool will take! As a matter of fact, NOT
performing a dry-run on a system is just plain irresponsible!"</p>

<p>Not exactly.</p>

<p>The <a href=http://pubs.opengroup.org/onlinepubs/009695399/utilities/make.html">make</a>
utility is the earliest example I can find of an automation tool with
a dry-run option. Make is usually used to build software. It calls
compilers, assemblers, linkers, check timestamps, and copy files around the filesystem.</p>

<p>Dry-run mode in <code>make -n</code> works by building a list of commands, then
printing instead of executing them. This is super useful because it
can be trusted that <code>make</code> will always execute the exact same list in
real-run mode. Every. Single. Time.</p>

<p>Rsync's dry-run mode behaves the same way. The command <code>rsync -n</code> will
print a list of files it needs to copy, and <code>rsync</code> will copy the
exact same list. The procedural nature of <code>rsync</code> and <code>make</code> allow this
to work. Build a list of actions to take, then print them out. Build a
list of actions and execute them instead. Easy.</p>

<p>Configuration Management tools, however, don't build lists of raw
commands. They build sets of convergent operators instead.</p>

<h2> Convergent Operators </h2>


<p>{% img right http://i.imgur.com/x3uWr.png 300 %}</p>

<p>The base building blocks of configuration management systems are executable
data structures known as "convergent operators". Puppet and Chef refer
to them as resources, while CFEngine calls them promises.</p>

<p>Convergent operators allow you to declare state. They are composed of
a subject and two sets of instructions. The first  set are tests that
determine if the subject is in the desired state, and the second set
are actions that will fix it if it's not. We make  "types" by grouping
common sets of tests and actions. This allows us to zoom out a level
and talk about things like files, services, users, groups and jobs
abstractly.</p>

<p>CFEngine promise bundles, Puppet manifests, and Chef recipes are all
sets of these data structures. Putting them into a <a
href="http://en.wikipedia.org/wiki/Control_theory">feedback loop</a>
allows for cooperation over multiple runs, as well as enabling the
self-healing properties that are essential when dealing with large
amounts of complexity.</p>

<h2> Promises and Lies </h2>


<p>{% img left http://i.imgur.com/rUk4d.png 350 %}
CFEngine 3 introduced
<a href="http://en.wikipedia.org/wiki/Promise_theory">Promise Theory</a>
as a way of modeling systems management. In this model, convergent
operators are described as autonomous agents that make "promises" and
cooperate with each other to configure machines.</p>

<p>While Puppet and Chef are not directly modeling promise theory
(they both lack the formal notion of "promiser and promisee"), they are
both inspired by CFEngine 2, and therefore share the same convergent DNA.
It is still very useful to think of a Chef or Puppet resource as an
individual, stand-alone agent that promises to fix the thing it's
concerned about.</p>

<p>When writing my day-to-day Chef cookbooks, I personally imagine every resource
statement I make (or generate) as a little robotic Lego man. Each time the
feedback loop runs, the Lego man's left hand runs tests that interrogate
package managers, inspect files, and examine processes tables. The
right hand  moves only when it needs to make corrections. Recipes
unleash swarms of these little robotic promise makers, each spinning
around dizzily repairing machines.</p>

<p>By personifying our configuration agents, it is easier to imagine them
lying to you. This raises a few questions. "Why would they lie to
me?", you might ask yourself. Under what circumstances are they likely
to lie? What exactly is a lie anyway?</p>

<p>It turns out that a <a
href="http://cfengine.com/markburgess/BookOfPromises.pdf">formal</a>
examination of promises does indeed include the notion of lies. Lies
can be outright deceptions, which are the lies of the
rarely-encountered Evil Robots. Lies can also be "non-deceptions",
which are the lies of occasionally-encountered Broken Robots. Most
often though, we experience lies from the often-encountered Merely
Mis-informed Robots.</p>

<h2> Sets and Sequence </h2>


<p>During a run, each tool applies <em>ordered sets</em> of convergent
operators against the system. How this order is determined varies from
tool to tool, but it is ordered none the less.</p>

<p>{% img right http://i.imgur.com/g4fcW.png 300 %}</p>

<p>CFEngine uses a system called 'normal ordering' to determine sequence, while Puppet
sorts graphs. Chef compiles a resource collection by evaluatiing
recipes imperatively.</p>

<p>{% img right http://i.imgur.com/uKQHY.png 300 %}</p>

<p>Sequence ordering is typically important within promise bundles,
modules, and recipes. Ordering is sometimes important between the sets
themselves, but not usually. Thinking at this level allows us to
effectively reason about the mechanics of dry-run mode.</p>

<h2> The Best You Can Do </h2>


<p>{% img left http://i.imgur.com/oyf5b.png 300 %}</p>

<p>The best you can possibly hope to do in a dry-run mode is to build the operator
sequences, run all the tests, then report back what each agent would
do at that exact moment. The problem with this is, in real-run mode, the
<em>The system is changing between the tests</em>. Quite often, the results
of any given test will be affected by a preceeding action.</p>

<p>Configuration operations can have rather large side effects on machine
state. Sending signals to processes can result in files being changed
on disk. Mounting a disk changes an entire branch of a directory tree.
Packages can drop off one or a million different files and will often
execute arbitrary commands contained in 'pre' and 'post' scripts.
Installing the Postfix package on an Ubuntu system will not only write
the package contents to disk, but also create users and disable Exim
before automatically starting the service.</p>

<p>Throw in some resource notifications and random boolean checks and
things can get really interesting.</p>

<h2> Lies of the Legomen </h2>


<p>{% img right http://i.imgur.com/4ORuB.jpg 250 350 %}</p>

<p>To experiment with dry-run mode, I made a Chef cookbook that
configures a machine with initial conditions, then drops off CFEngine
and Puppet policies for dry-running.</p>

<p>We will see CFEngine, Puppet, and Chef running in their respective
dry-run modes, stating that they will take some actions, immediately
followed by real-run doing mode taking some others.</p>

<p>Three configuration management systems, each with conflicting
policies, wreaking havoc on a single machine sounds like a fun way to
spend the evening. Lets get weird.</p>

<p>If you already have Vagrant setup and would like to follow along, feel free.
Check out the cookbook
<a href='https://github.com/someara/dry-run-lies-cookbook'>here</a>. Otherwise,
you can just read the code examples by clicking on the provided links as we go.</p>

<p>Begin by checking out the dry-run cookbook from git, then configure a
Vagrant box with Chef.</p>

<p>{% codeblock %}
~/src/$ git clone https://github.com/someara/dry-run-lies-cookbook dry-run-lies
~/src/$ cd dry-run-lies
~/src/dry-run-lies$ bundle exec vagrant up
~/src/dry-run-lies$ bundle exec vagrant ssh
{% endcodeblock %}</p>

<h2> CFEngine Example </h2>


<p>After Chef has configured our machine, we can log into it, switch to
root, then run <code>cf-agent</code> with the <code>-n</code> flag to see what dry-run thinks
it will do to the system.</p>

<p>{% codeblock CFEngine dry-run  %}
root@dry-run-lies:~# cf-agent -K -f /tmp/lies-1.cf -n
-> Would execute script /bin/echo hello from bundle_one. puppet_bin_does_not_exist
 -> Need to execute /usr/bin/aptitude update...
{% endcodeblock %}</p>

<p>Here we see that there is a promise yet to be kept in bundle_one. Very
good. Let's remove <code>-n</code> and watch it do just that.</p>

<p>{% codeblock CFEngine real-run  %}
root@dry-run-lies:~# cf-agent -K -f /tmp/lies-1.cf
Q: ".../bin/echo hello": hello from bundle_one.
puppet_bin_does_not_exist
I: Last 1 quoted lines were generated by promiser "/bin/echo hello from bundle_one. puppet_bin_does_not_exist"
Q: ".../bin/echo hello": hello from bundle_three. puppet_bin_exists
I: Last 1 quoted lines were generated by promiser "/bin/echo hello from bundle_three. puppet_bin_exists"
{% endcodeblock %}</p>

<p>Wait a sec... Whats all this bundle_three business? Did dry-run just
lie to me?</p>

<p>Let's look at a CFEngine code snippet and see what happened. You can view the entire <code>lies-1.cf</code> file <a
href="http://bit.ly/RVnV38">here</a>.</p>

<p>{% codeblock lies-1.cf lang:ruby %}
bundle agent bundle_one
{
classes:
  "puppet_bin_exists" expression =></p>

<pre><code>returnszero("/usr/bin/test -e /usr/bin/puppet", "noshell");
</code></pre>

<p>commands:
  "/bin/echo"</p>

<pre><code>args =&gt; "hello from bundle_one.
puppet_bin_does_not_exist.",
ifvarclass =&gt; "!puppet_bin_exists";
</code></pre>

<p>}</p>

<p>bundle agent bundle_two
{
packages:
  "puppet"</p>

<pre><code>comment =&gt; "puppet",
package_policy =&gt; "add",
package_method =&gt; apt,
classes =&gt; if_repaired("puppet_bin_exists");
</code></pre>

<p>}</p>

<p>bundle agent bundle_three
{
classes:
  "puppet_bin_exists" expression =></p>

<pre><code>returnszero("/usr/bin/test -e /usr/bin/puppet", "noshell");
</code></pre>

<p>commands:
  "/bin/echo"</p>

<pre><code>args =&gt; "hello from bundle_three. puppet_bin_exists.",
ifvarclass =&gt; "puppet_bin_exists";
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>During the dry-run, the test in the bundle_three came back negative.
The actions in bundle_two had yet to change the state of the machine.
By the time it got to bundle_three in the real-run, the system had
changed enough to affect the outcome of the tests.</p>

<h2> Puppet Example </h2>


<p>Let's give Puppet a spin. We can apply a local policy with the
<code>--noop</code> flag to see what Puppet thinks it will do.</p>

<p>{% codeblock Puppet dry-run  %}
root@dry-run-lies:~# puppet apply /tmp/lies-1.pp --noop
notice: /Stage[main]//Mount[/mnt/nfsmount]/ensure: current_value ghost, should be unmounted (noop)
notice: /Stage[main]//Mount[/mnt/nfsmount]: Would have triggered 'refresh' from 1 events
notice: Class[Main]: Would have triggered 'refresh' from 3 events
notice: Stage[main]: Would have triggered 'refresh' from 1 events
notice: Finished catalog run in 0.30 seconds
{% endcodeblock %}</p>

<p>One resource to fix. Excellent. A very small, safe change to the
system for sure. Let's remove the <code>--noop</code>.</p>

<p>{% codeblock Puppet real-run %}
root@dry-run-lies:~# puppet apply /tmp/lies-1.pp
notice: /Stage[main]//Mount[/mnt/nfsmount]/ensure: ensure changed 'ghost' to 'unmounted'
notice: /Stage[main]//Mount[/mnt/nfsmount]: Triggered 'refresh' from 1 events
notice: /Stage[main]//File[/mnt/nfsmount/file-1]/ensure: created
notice: /Stage[main]//File[/mnt/nfsmount/file-2]/ensure: created
notice: /Stage[main]//File[/mnt/nfsmount/file-3]/ensure: created
notice: Finished catalog run in 4.37 seconds
{% endcodeblock %}</p>

<p>"What the....?" Real-run created three files! Luckily it didn't do
anything too crazy on my Very Important Production System. Let's take
a look at some <a href="http://bit.ly/V87wom">code</a> and figure out
whats going on.</p>

<p>{% codeblock lies-1.pp lang:ruby %}
package { "nmap":
  ensure => absent;
}</p>

<p>mount { "/mnt/nfsmount":
  device => "127.0.0.1:/srv/nfssrv",
  fstype => "nfs",
  ensure  => "unmounted",
  options => "defaults",
  atboot  => true,
 }</p>

<p>file { "/mnt/nfsmount/file-1":
  ensure => present,
  require => Mount["/mnt/nfsmount"];
}</p>

<p>file { "/mnt/nfsmount/file-2":
  ensure => present,
  require => Mount["/mnt/nfsmount"];
}</p>

<p>file { "/mnt/nfsmount/file-3":
  ensure => present;
}
{% endcodeblock %}</p>

<p>Again, as with the CFEngine example, we have Puppet changing machine
state between tests. The Chef recipe that set up the initial machine
state exported and mounted an NFS share. Puppet unmounts the
directory, changing the view of the filesystem.</p>

<p>It should be noted that Puppet's resource graph model does nothing to
enable noop functionality, nor can it affect its accuracy. It used
only for the purposes of ordering and ensuring non-conflicting node
names within its model.</p>

<h2> Chef Example </h2>


<p>Finally, we'll run the original Chef policy that set up the machine
with the <code>-W</code> flag and see if it lies like the others.</p>

<p>{% codeblock %}
root@dry-run-lies:~# chef-solo -c /tmp/vagrant-chef-1/solo.rb -j /tmp/vagrant-chef-1/dna.json -Fmin --why-run
Starting Chef Client, version 10.16.4
Compiling cookbooks .......done.
Converging 32 resources .........................U.......UUUS
System converged.</p>

<p>resources updated this run:
* mount[/mnt/nfsmount]
- mount 127.0.0.1:/srv/nfssrv to /mnt/nfsmount</p>

<ul>
<li>package[nmap]</li>
<li><p>install version 5.21-1.1ubuntu1 of package nmap</p></li>
<li><p>package[puppet]</p></li>
<li>remove  package puppet</li>
<li><p>purge  package puppet</p></li>
<li><p>package[puppet-common]</p></li>
<li>remove  package puppet-common</li>
<li>purge  package puppet-common</li>
</ul>


<p>chef client finished, 4 resources updated
{% endcodeblock %}</p>

<p>Seems reasonable. Let's remove the <code>--why-run</code> flag and do it for real.</p>

<p>{% codeblock %}
root@dry-run-lies:~# chef-solo -c /tmp/vagrant-chef-1/solo.rb -j /tmp/vagrant-chef-1/dna.json -Fmin
Starting Chef Client, version 10.16.4
Compiling cookbooks .......done.
Converging 32 resources .........................U.......UUUU
System converged.</p>

<p>resources updated this run:
* mount[/mnt/nfsmount]
- mount 127.0.0.1:/srv/nfssrv to /mnt/nfsmount</p>

<ul>
<li>package[nmap]</li>
<li><p>install version 5.21-1.1ubuntu1 of package nmap</p></li>
<li><p>package[puppet]</p></li>
<li><p>remove  package puppet</p></li>
<li><p>package[puppet-common]</p></li>
<li><p>remove  package puppet-common</p></li>
<li><p>execute[hack the planet]</p></li>
<li>execute /bin/echo HACKING THE PLANET</li>
</ul>


<p>chef client finished, 5 resources updated
{% endcodeblock %}</p>

<p>Right. "HACKING THE PLANET" was definitely not in the dry-run output.
Let's go figure out what happened. See the entire Chef recipe <a href="http://bit.ly/WXr8k0">here</a>.</p>

<p>{% codeblock recipes/default.rb %}</p>

<h1><snip></h1>

<p>package "nmap" do
  only_if "/usr/bin/test -f /usr/bin/puppet"
end</p>

<p>package "puppet" do
  action [:remove, :purge]
end</p>

<p>package "puppet-common" do
  action [:remove, :purge]
end</p>

<p>#
execute "hack the planet" do
  command "/bin/echo HACKING THE PLANET"
  only_if "/usr/bin/test -f /usr/bin/nmap"
end
{% endcodeblock %}</p>

<p>Previously, our CFEngine policy had installed Puppet on the machine.
Our Puppet policy ensured nmap was absent. Chef will install nmap,
but only if the Puppet binary is present in /usr/bin.</p>

<p>In <code>--why-run</code> mode, the test for the <code>'package[nmap]'</code> resource
succeeds because of the pre-conditions set up by the CFEngine policy.
Had we not applied that policy, the <code>'execute[hack the planet]'</code>
resource would still not have fired because nothing had installed the
nmap package along the way. In real-run mode, it succeeds because Chef
changes the machine state between tests, but would have failed if we
had never ran the Puppet policy.</p>

<p>Yikes.</p>

<h2> Okay, So What? </h2>


<p>The Lego men were not trying to be deceptive. Each autonomous agent
told us what it honestly thought it should do in order to fix the
system. As far as they could see, everything was fine when we asked
them.</p>

<p>As we automate the world around us, it is important to know how the
systems we build fail. We are going to need to fix them, after all.
It is even more important to know when and how our machines lie to us.
The last thing we need is an army of lying robots wandering around.</p>

<p>The good news is that the examples I used were a bit contrived and
took me a while to think up. However, configuration management is
being adopted very rapidly. The larger and more complex our policies
become, the higher the chances of confusion.</p>

<p>Luckily, there are a number of techniques for testing and introducing
change that can be used to help ensure nothing bad happens.</p>

<h2> Keeping the Machines Honest </h2>


<p>{% img right http://farm8.staticflickr.com/7171/6809694353_7bdba3a38a_n.jpg 280 %}</p>

<p>In each case, the system converged to the prescribed policy, regardless of
whether dry-run got confused or not. If we can reproduce a system's
pre-conditions, we can simply real-run the policy and observe the behavior. Tests
can then be ran to ensure that the new machine state is doing what it's supposed to.</p>

<p>Ideally, test machines are modeled with CM policy from the ground up, starting
with Just Enough Operating System to allow them to run a CM tool. This ensures
all the details of the system have been captured and are reproducable.</p>

<p>Other ways of reproducing pre-conditons work, but come with the
burden of having to drag that knowledge around with you. Snapshots,
kickstart or bootstrap scripts, and even manual configuration will all
work so long as you can promise they're accurate.</p>

<p>There are some situations where reproducing a test system is impossible, or
modeling it from the ground up is not an option. In this case, a slow, careful,
incremental application of policy, aided by dry-run mode and human intuition is
the safest way to start to bring order to chaos. Chef's why-run mode
can help aide intuition by publishing assumptions about what's going
on. "I would start the service, assuming the software had been
previously installed" helps, but is no panacea. At some point you have
to blindly trust fate.</p>

<p>Finally, increasing the resolution of our policies will help the most in the long
term. The more Lego men, the better. Ensuring the contents of configuration files
is good. Making sure that they are only ones present in a conf.d directory is
better. As a community, we need to produce as much high quality, trusted, tested,
and reuseable policy as possible.</p>

<p>Good luck, and be careful out there.</p>

<p>-s</p>
]]></content>
  </entry>
  
</feed>
