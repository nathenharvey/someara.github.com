<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Chef | A Fistful of Servers]]></title>
  <link href="http://someara.github.com/blog/categories/chef/atom.xml" rel="self"/>
  <link href="http://someara.github.com/"/>
  <updated>2012-12-30T12:19:28-05:00</updated>
  <id>http://someara.github.com/</id>
  <author>
    <name><![CDATA[Sean OMeara]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Promises, Lies, and Dry-Run Mode]]></title>
    <link href="http://someara.github.com/post/2012/12/21/promises-lies-and-dryrun-mode/"/>
    <updated>2012-12-21T04:20:00-05:00</updated>
    <id>http://someara.github.com/post/2012/12/21/promises-lies-and-dryrun-mode</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>


<p>{% img right http://i.imgur.com/Ftyot.jpg 300 %}</p>

<p>"I need to know what this will do to my production system before I run
it." -- Ask a Systems Administrator why they want dry-run mode in a configuration
management tool, and this is the answer you'll get almost every single time.</p>

<p>Systems Administrators have historically been able to use dry-run as a
risk mitigation strategy before applying changes to their machines.
The idea is to test a command to determine if it is safe to run.
Unfortunately, this only works if a tool's dry-run reporting can be
trusted as accurate.</p>

<p>In this post, I'll break down how modern configuration management
tools are very different animals than the  classical tool set, and why
dry-run mode is less than completely trustworthy. I'll provide
examples of dry-run saying one thing, and real-run doing another. The
takeaway should be that dry-run, while useful for development, should
never be used alone in place of proper testing.</p>

<h2> make -n </h2>


<p>{% img left http://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Ford_assembly_line<em>-</em>1913.jpg/566px-Ford_assembly_line<em>-</em>1913.jpg 300 %}</p>

<p>Many tools in a sysadmin's belt have a dry-run mode. Common
utilities like make, rsync, rpm, and apt all have it.  Many databases
will let you simulate updates, and most disk utilities can show you
changes before making them.</p>

<p>"People have been doing this for years! It should be easy to get a
list of what actions a tool will take! As a matter of fact, NOT
performing a dry-run on a system is just plain irresponsible!"</p>

<p>Not exactly.</p>

<p>The <a href=http://pubs.opengroup.org/onlinepubs/009695399/utilities/make.html">make</a>
utility is the earliest example I can find of an automation tool with
a dry-run option. Make is usually used to build software. It calls
compilers, assemblers, linkers, check timestamps, and copy files around the filesystem.</p>

<p>Dry-run mode in <code>make -n</code> works by building a list of commands, then
printing instead of executing them. This is super useful because it
can be trusted that <code>make</code> will always execute the exact same list in
real-run mode. Every. Single. Time.</p>

<p>Rsync's dry-run mode behaves the same way. The command <code>rsync -n</code> will
print a list of files it needs to copy, and <code>rsync</code> will copy the
exact same list. The procedural nature of <code>rsync</code> and <code>make</code> allow this
to work. Build a list of actions to take, then print them out. Build a
list of actions and execute them instead. Easy.</p>

<p>Configuration Management tools, however, don't build lists of raw
commands. They build sets of convergent operators instead.</p>

<h2> Convergent Operators </h2>


<p>{% img right http://i.imgur.com/x3uWr.png 300 %}</p>

<p>The base building blocks of configuration management systems are executable
data structures known as "convergent operators". Puppet and Chef refer
to them as resources, while CFEngine calls them promises.</p>

<p>Convergent operators allow you to declare state. They are composed of
a subject and two sets of instructions. The first  set are tests that
determine if the subject is in the desired state, and the second set
are actions that will fix it if it's not. We make  "types" by grouping
common sets of tests and actions. This allows us to zoom out a level
and talk about things like files, services, users, groups and jobs
abstractly.</p>

<p>CFEngine promise bundles, Puppet manifests, and Chef recipes are all
sets of these data structures. Putting them into a <a
href="http://en.wikipedia.org/wiki/Control_theory">feedback loop</a>
allows for cooperation over multiple runs, as well as enabling the
self-healing properties that are essential when dealing with large
amounts of complexity.</p>

<h2> Promises and Lies </h2>


<p>{% img left http://i.imgur.com/rUk4d.png 350 %}
CFEngine 3 introduced
<a href="http://en.wikipedia.org/wiki/Promise_theory">Promise Theory</a>
as a way of modeling systems management. In this model, convergent
operators are described as autonomous agents that make "promises" and
cooperate with each other to configure machines.</p>

<p>While Puppet and Chef are not directly modeling promise theory
(they both lack the formal notion of "promiser and promisee"), they are
both inspired by CFEngine 2, and therefore share the same convergent DNA.
It is still very useful to think of a Chef or Puppet resource as an
individual, stand-alone agent that promises to fix the thing it's
concerned about.</p>

<p>When writing my day-to-day Chef cookbooks, I personally imagine every resource
statement I make (or generate) as a little robotic Lego man. Each time the
feedback loop runs, the Lego man's left hand runs tests that interrogate
package managers, inspect files, and examine processes tables. The
right hand  moves only when it needs to make corrections. Recipes
unleash swarms of these little robotic promise makers, each spinning
around dizzily repairing machines.</p>

<p>By personifying our configuration agents, it is easier to imagine them
lying to you. This raises a few questions. "Why would they lie to
me?", you might ask yourself. Under what circumstances are they likely
to lie? What exactly is a lie anyway?</p>

<p>It turns out that a <a
href="http://cfengine.com/markburgess/BookOfPromises.pdf">formal</a>
examination of promises does indeed include the notion of lies. Lies
can be outright deceptions, which are the lies of the
rarely-encountered Evil Robots. Lies can also be "non-deceptions",
which are the lies of occasionally-encountered Broken Robots. Most
often though, we experience lies from the often-encountered Merely
Mis-informed Robots.</p>

<h2> Sets and Sequence </h2>


<p>During a run, each tool applies <em>ordered sets</em> of convergent
operators against the system. How this order is determined varies from
tool to tool, but it is ordered none the less.</p>

<p>{% img right http://i.imgur.com/g4fcW.png 300 %}</p>

<p>CFEngine uses a system called 'normal ordering' to determine sequence, while Puppet
sorts graphs. Chef compiles a resource collection by evaluatiing
recipes imperatively.</p>

<p>{% img right http://i.imgur.com/uKQHY.png 300 %}</p>

<p>Sequence ordering is typically important within promise bundles,
modules, and recipes. Ordering is sometimes important between the sets
themselves, but not usually. Thinking at this level allows us to
effectively reason about the mechanics of dry-run mode.</p>

<h2> The Best You Can Do </h2>


<p>{% img left http://i.imgur.com/oyf5b.png 300 %}</p>

<p>The best you can possibly hope to do in a dry-run mode is to build the operator
sequences, run all the tests, then report back what each agent would
do at that exact moment. The problem with this is, in real-run mode, the
<em>The system is changing between the tests</em>. Quite often, the results
of any given test will be affected by a preceeding action.</p>

<p>Configuration operations can have rather large side effects on machine
state. Sending signals to processes can result in files being changed
on disk. Mounting a disk changes an entire branch of a directory tree.
Packages can drop off one or a million different files and will often
execute arbitrary commands contained in 'pre' and 'post' scripts.
Installing the Postfix package on an Ubuntu system will not only write
the package contents to disk, but also create users and disable Exim
before automatically starting the service.</p>

<p>Throw in some resource notifications and random boolean checks and
things can get really interesting.</p>

<h2> Lies of the Legomen </h2>


<p>{% img right http://i.imgur.com/4ORuB.jpg 250 350 %}</p>

<p>To experiment with dry-run mode, I made a Chef cookbook that
configures a machine with initial conditions, then drops off CFEngine
and Puppet policies for dry-running.</p>

<p>We will see CFEngine, Puppet, and Chef running in their respective
dry-run modes, stating that they will take some actions, immediately
followed by real-run doing mode taking some others.</p>

<p>Three configuration management systems, each with conflicting
policies, wreaking havoc on a single machine sounds like a fun way to
spend the evening. Lets get weird.</p>

<p>If you already have Vagrant setup and would like to follow along, feel free.
Check out the cookbook
<a href='https://github.com/someara/dry-run-lies-cookbook'>here</a>. Otherwise,
you can just read the code examples by clicking on the provided links as we go.</p>

<p>Begin by checking out the dry-run cookbook from git, then configure a
Vagrant box with Chef.</p>

<p>{% codeblock %}
~/src/$ git clone https://github.com/someara/dry-run-lies-cookbook dry-run-lies
~/src/$ cd dry-run-lies
~/src/dry-run-lies$ bundle exec vagrant up
~/src/dry-run-lies$ bundle exec vagrant ssh
{% endcodeblock %}</p>

<h2> CFEngine Example </h2>


<p>After Chef has configured our machine, we can log into it, switch to
root, then run <code>cf-agent</code> with the <code>-n</code> flag to see what dry-run thinks
it will do to the system.</p>

<p>{% codeblock CFEngine dry-run  %}
root@dry-run-lies:~# cf-agent -K -f /tmp/lies-1.cf -n
-> Would execute script /bin/echo hello from bundle_one. puppet_bin_does_not_exist
 -> Need to execute /usr/bin/aptitude update...
{% endcodeblock %}</p>

<p>Here we see that there is a promise yet to be kept in bundle_one. Very
good. Let's remove <code>-n</code> and watch it do just that.</p>

<p>{% codeblock CFEngine real-run  %}
root@dry-run-lies:~# cf-agent -K -f /tmp/lies-1.cf
Q: ".../bin/echo hello": hello from bundle_one.
puppet_bin_does_not_exist
I: Last 1 quoted lines were generated by promiser "/bin/echo hello from bundle_one. puppet_bin_does_not_exist"
Q: ".../bin/echo hello": hello from bundle_three. puppet_bin_exists
I: Last 1 quoted lines were generated by promiser "/bin/echo hello from bundle_three. puppet_bin_exists"
{% endcodeblock %}</p>

<p>Wait a sec... Whats all this bundle_three business? Did dry-run just
lie to me?</p>

<p>Let's look at a CFEngine code snippet and see what happened. You can view the entire <code>lies-1.cf</code> file <a
href="http://bit.ly/RVnV38">here</a>.</p>

<p>{% codeblock lies-1.cf lang:ruby %}
bundle agent bundle_one
{
classes:
  "puppet_bin_exists" expression =></p>

<pre><code>returnszero("/usr/bin/test -e /usr/bin/puppet", "noshell");
</code></pre>

<p>commands:
  "/bin/echo"</p>

<pre><code>args =&gt; "hello from bundle_one.
puppet_bin_does_not_exist.",
ifvarclass =&gt; "!puppet_bin_exists";
</code></pre>

<p>}</p>

<p>bundle agent bundle_two
{
packages:
  "puppet"</p>

<pre><code>comment =&gt; "puppet",
package_policy =&gt; "add",
package_method =&gt; apt,
classes =&gt; if_repaired("puppet_bin_exists");
</code></pre>

<p>}</p>

<p>bundle agent bundle_three
{
classes:
  "puppet_bin_exists" expression =></p>

<pre><code>returnszero("/usr/bin/test -e /usr/bin/puppet", "noshell");
</code></pre>

<p>commands:
  "/bin/echo"</p>

<pre><code>args =&gt; "hello from bundle_three. puppet_bin_exists.",
ifvarclass =&gt; "puppet_bin_exists";
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>During the dry-run, the test in the bundle_three came back negative.
The actions in bundle_two had yet to change the state of the machine.
By the time it got to bundle_three in the real-run, the system had
changed enough to affect the outcome of the tests.</p>

<h2> Puppet Example </h2>


<p>Let's give Puppet a spin. We can apply a local policy with the
<code>--noop</code> flag to see what Puppet thinks it will do.</p>

<p>{% codeblock Puppet dry-run  %}
root@dry-run-lies:~# puppet apply /tmp/lies-1.pp --noop
notice: /Stage[main]//Mount[/mnt/nfsmount]/ensure: current_value ghost, should be unmounted (noop)
notice: /Stage[main]//Mount[/mnt/nfsmount]: Would have triggered 'refresh' from 1 events
notice: Class[Main]: Would have triggered 'refresh' from 3 events
notice: Stage[main]: Would have triggered 'refresh' from 1 events
notice: Finished catalog run in 0.30 seconds
{% endcodeblock %}</p>

<p>One resource to fix. Excellent. A very small, safe change to the
system for sure. Let's remove the <code>--noop</code>.</p>

<p>{% codeblock Puppet real-run %}
root@dry-run-lies:~# puppet apply /tmp/lies-1.pp
notice: /Stage[main]//Mount[/mnt/nfsmount]/ensure: ensure changed 'ghost' to 'unmounted'
notice: /Stage[main]//Mount[/mnt/nfsmount]: Triggered 'refresh' from 1 events
notice: /Stage[main]//File[/mnt/nfsmount/file-1]/ensure: created
notice: /Stage[main]//File[/mnt/nfsmount/file-2]/ensure: created
notice: /Stage[main]//File[/mnt/nfsmount/file-3]/ensure: created
notice: Finished catalog run in 4.37 seconds
{% endcodeblock %}</p>

<p>"What the....?" Real-run created three files! Luckily it didn't do
anything too crazy on my Very Important Production System. Let's take
a look at some <a href="http://bit.ly/V87wom">code</a> and figure out
whats going on.</p>

<p>{% codeblock lies-1.pp lang:ruby %}
package { "nmap":
  ensure => absent;
}</p>

<p>mount { "/mnt/nfsmount":
  device => "127.0.0.1:/srv/nfssrv",
  fstype => "nfs",
  ensure  => "unmounted",
  options => "defaults",
  atboot  => true,
 }</p>

<p>file { "/mnt/nfsmount/file-1":
  ensure => present,
  require => Mount["/mnt/nfsmount"];
}</p>

<p>file { "/mnt/nfsmount/file-2":
  ensure => present,
  require => Mount["/mnt/nfsmount"];
}</p>

<p>file { "/mnt/nfsmount/file-3":
  ensure => present;
}
{% endcodeblock %}</p>

<p>Again, as with the CFEngine example, we have Puppet changing machine
state between tests. The Chef recipe that set up the initial machine
state exported and mounted an NFS share. Puppet unmounts the
directory, changing the view of the filesystem.</p>

<p>It should be noted that Puppet's resource graph model does nothing to
enable noop functionality, nor can it affect its accuracy. It used
only for the purposes of ordering and ensuring non-conflicting node
names within its model.</p>

<h2> Chef Example </h2>


<p>Finally, we'll run the original Chef policy that set up the machine
with the <code>-W</code> flag and see if it lies like the others.</p>

<p>{% codeblock %}
root@dry-run-lies:~# chef-solo -c /tmp/vagrant-chef-1/solo.rb -j /tmp/vagrant-chef-1/dna.json -Fmin --why-run
Starting Chef Client, version 10.16.4
Compiling cookbooks .......done.
Converging 32 resources .........................U.......UUUS
System converged.</p>

<p>resources updated this run:
* mount[/mnt/nfsmount]
- mount 127.0.0.1:/srv/nfssrv to /mnt/nfsmount</p>

<ul>
<li>package[nmap]</li>
<li><p>install version 5.21-1.1ubuntu1 of package nmap</p></li>
<li><p>package[puppet]</p></li>
<li>remove  package puppet</li>
<li><p>purge  package puppet</p></li>
<li><p>package[puppet-common]</p></li>
<li>remove  package puppet-common</li>
<li>purge  package puppet-common</li>
</ul>


<p>chef client finished, 4 resources updated
{% endcodeblock %}</p>

<p>Seems reasonable. Let's remove the <code>--why-run</code> flag and do it for real.</p>

<p>{% codeblock %}
root@dry-run-lies:~# chef-solo -c /tmp/vagrant-chef-1/solo.rb -j /tmp/vagrant-chef-1/dna.json -Fmin
Starting Chef Client, version 10.16.4
Compiling cookbooks .......done.
Converging 32 resources .........................U.......UUUU
System converged.</p>

<p>resources updated this run:
* mount[/mnt/nfsmount]
- mount 127.0.0.1:/srv/nfssrv to /mnt/nfsmount</p>

<ul>
<li>package[nmap]</li>
<li><p>install version 5.21-1.1ubuntu1 of package nmap</p></li>
<li><p>package[puppet]</p></li>
<li><p>remove  package puppet</p></li>
<li><p>package[puppet-common]</p></li>
<li><p>remove  package puppet-common</p></li>
<li><p>execute[hack the planet]</p></li>
<li>execute /bin/echo HACKING THE PLANET</li>
</ul>


<p>chef client finished, 5 resources updated
{% endcodeblock %}</p>

<p>Right. "HACKING THE PLANET" was definitely not in the dry-run output.
Let's go figure out what happened. See the entire Chef recipe <a href="http://bit.ly/WXr8k0">here</a>.</p>

<p>{% codeblock recipes/default.rb %}</p>

<h1><snip></h1>

<p>package "nmap" do
  only_if "/usr/bin/test -f /usr/bin/puppet"
end</p>

<p>package "puppet" do
  action [:remove, :purge]
end</p>

<p>package "puppet-common" do
  action [:remove, :purge]
end</p>

<p>#
execute "hack the planet" do
  command "/bin/echo HACKING THE PLANET"
  only_if "/usr/bin/test -f /usr/bin/nmap"
end
{% endcodeblock %}</p>

<p>Previously, our CFEngine policy had installed Puppet on the machine.
Our Puppet policy ensured nmap was absent. Chef will install nmap,
but only if the Puppet binary is present in /usr/bin.</p>

<p>In <code>--why-run</code> mode, the test for the <code>'package[nmap]'</code> resource
succeeds because of the pre-conditions set up by the CFEngine policy.
Had we not applied that policy, the <code>'execute[hack the planet]'</code>
resource would still not have fired because nothing had installed the
nmap package along the way. In real-run mode, it succeeds because Chef
changes the machine state between tests, but would have failed if we
had never ran the Puppet policy.</p>

<p>Yikes.</p>

<h2> Okay, So What? </h2>


<p>The Lego men were not trying to be deceptive. Each autonomous agent
told us what it honestly thought it should do in order to fix the
system. As far as they could see, everything was fine when we asked
them.</p>

<p>As we automate the world around us, it is important to know how the
systems we build fail. We are going to need to fix them, after all.
It is even more important to know when and how our machines lie to us.
The last thing we need is an army of lying robots wandering around.</p>

<p>The good news is that the examples I used were a bit contrived and
took me a while to think up. However, configuration management is
being adopted very rapidly. The larger and more complex our policies
become, the higher the chances of confusion.</p>

<p>Luckily, there are a number of techniques for testing and introducing
change that can be used to help ensure nothing bad happens.</p>

<h2> Keeping the Machines Honest </h2>


<p>{% img right http://farm8.staticflickr.com/7171/6809694353_7bdba3a38a_n.jpg 280 %}</p>

<p>In each case, the system converged to the prescribed policy, regardless of
whether dry-run got confused or not. If we can reproduce a system's
pre-conditions, we can simply real-run the policy and observe the behavior. Tests
can then be ran to ensure that the new machine state is doing what it's supposed to.</p>

<p>Ideally, test machines are modeled with CM policy from the ground up, starting
with Just Enough Operating System to allow them to run a CM tool. This ensures
all the details of the system have been captured and are reproducable.</p>

<p>Other ways of reproducing pre-conditons work, but come with the
burden of having to drag that knowledge around with you. Snapshots,
kickstart or bootstrap scripts, and even manual configuration will all
work so long as you can promise they're accurate.</p>

<p>There are some situations where reproducing a test system is impossible, or
modeling it from the ground up is not an option. In this case, a slow, careful,
incremental application of policy, aided by dry-run mode and human intuition is
the safest way to start to bring order to chaos. Chef's why-run mode
can help aide intuition by publishing assumptions about what's going
on. "I would start the service, assuming the software had been
previously installed" helps, but is no panacea. At some point you have
to blindly trust fate.</p>

<p>Finally, increasing the resolution of our policies will help the most in the long
term. The more Lego men, the better. Ensuring the contents of configuration files
is good. Making sure that they are only ones present in a conf.d directory is
better. As a community, we need to produce as much high quality, trusted, tested,
and reuseable policy as possible.</p>

<p>Good luck, and be careful out there.</p>

<p>-s</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CFEngine Puppet and Chef Part 3]]></title>
    <link href="http://someara.github.com/post/2011/12/30/cfengine-puppet-and-chef-part-3/"/>
    <updated>2011-12-30T20:11:00-05:00</updated>
    <id>http://someara.github.com/post/2011/12/30/cfengine-puppet-and-chef-part-3</id>
    <content type="html"><![CDATA[<p>At the end of the last installment, we used Puppet to create a Chef server. That brings us full circle, and the only thing we have left to do is examine how Chef works. We'll do that by looking at the code that gave us our original CFEngine server.</p>

<h2> Chef </h2>


<p>{% img right http://farm4.staticflickr.com/3024/2417315604_ba73be6be2.jpg 300 300 %}</p>

<p>Since they're both written in Ruby, people tend to compare Puppet and Chef. This is natural since they have a lot in common. Both are convergence based configuration management tools inspired by CFEngine. Both have stand alone discovery agents (facter and ohai, respectively), as well as RESTful APIs for gleaning node information from the server. It turns out, however, that Chef actually has a lot more in common with CFEngine.</p>

<p>Like CFEngine, Chef copies policy from the server and evaluates it on the edges. This allows for high scalability, since the server isn't doing very much. Think of web application that does most of its work in the browser instead of on the server.</p>

<p>A Chef recipe is a collection of convergent <a href=http://wiki.opscode.com/display/chef/Resources target="_blank">resource</a> statements, and serves as the basic unit of intent. This is analogous to a CFEngine promise bundle. The Chef run list is how recipe ordering is defined, and is directly comparible to CFEngine's bundlesqeuence. Using this approach makes it easy to reason about what's going on when writing infrastructure as code.</p>

<h2> Chef Specials </h2>




<h3> Imperative programming and declarative interface </h3>


<p>While it's true that Chef is just "pure ruby" and therefore imperative, to say that Chef is imperative without considering the declarative interface to resources is disingenuous at best. Using nothing but Chef resources, recipes look very much like their CFEngine and Puppet counterparts. The non-optimally ordered Chef version of NTP converges in the same number of runs as the CFEngine example from the first installment. This is because the <a href=http://www.iu.hio.no/~mark/papers/immune.pdf target="_blank">underlying science</a> of convergent operators is the same.</p>

<p>{% codeblock lang:ruby %}</p>

<h1>service</h1>

<p>service "ntp" do
  action [ :enable, :start ]
  ignore_failure true
end</p>

<h1>file</h1>

<p>template "/etc/ntp.conf" do
  source "ntp.conf.erb"
  owner "root"
  group "root"
  mode 0644
  notifies :restart, "service[ntp]"
  ignore_failure true
end</p>

<h1>package</h1>

<p>package "ntp" do
  action :install
  ignore_failure true
end
{% endcodeblock %}</p>

<p><a href=http://bit.ly/vPixyI target="_blank">When and where order matters</a>, imperative ordering isolated within a recipe is the most intuitive way for sysadmins to accomplish tasks within the convergent model. "Install a package, edit a config file, and start the service" is how most people think about the task. Imperative ordering of declarative statements give the best of both worlds. When order does NOT matter, it's safe to re-arrange recipe ordering in the Chef run list.</p>

<h3> Multiphase execution </h3>


<p>The real trick to effective Chef cookbook development is to understand the <a href=http://wiki.opscode.com/display/chef/Anatomy+of+a+Chef+Run target="_blank">Anatomy of a Chef Run</a>. When a Chef recipe is evaluated in the compilation phase, encountered resources are added to the Resource Collection, which is an array of evaluated resources with deferred execution.</p>

<p>The compile phase of this recipe would add 99 uniquely named, 12 oz, convergent beer_bottles to the collection, and the configure phase would take them down and pass them around. Subsequent runs would do nothing.
{% codeblock lang:ruby thanks jtimberman! %}
size = ((2 * 3) * 4) / 2</p>

<p>99.downto(1) do |i|
  beer_bottle "bottle-#{i}" do</p>

<pre><code>oz size
action [ :take_down, :pass_around ]
</code></pre>

<p>  end
end
{% endcodeblock %}</p>

<p>The idea is that you can take advantage of the full power of Ruby to make decisions about what to declare about your resources. Most people just use the built in Chef APIs to consult chef-server for topology information about their infrastructure. However, there's nothing stopping you from importing random Ruby modules and accessing existing SQL databases instead.</p>

<p>Want to name name servers after your Facebook friends? <a href=http://rfacebook.rubyforge.org/ type="_blank">Go for it.</a> Want your MOTD to list all James Brown albums released between 1980 and 1990? <a href=https://github.com/buntine/discogs type="_blank">Not a problem</a>. The important part is that things are ultimately managed with a declarative, idempotent, and convergent resource interface.</p>

<h2> cfengine.rb </h2>


<p>Let's take a look at the recipe that gave us our original CFEngine server.</p>

<p>{% include_code lang:ruby cookbooks/cfengine/recipes/server.rb %}</p>

<h2> Topology management </h2>


<p>When a node is bootstrapped with Chef, a run list of roles or recipes is requested by the node itself. After that, the host is found by recipes running elsewhere in the infrastructure by <a href=http://bit.ly/vI5Z9l target="_blank">searching</a> for roles or attributes. This is contrasted from the CFEngine and Puppet techniques of matching classes based on a hostname, FQDN, IP, or other found information.</p>

<p>This approach has the effect of decoupling a node's name from its functionality. Line 10 in <code>cfengine.rb</code> above searches out node objects and later be passes them to the <code>promises-server.cf.erb</code> template for authorization.</p>

<h2> Wrapping up </h2>


<p>So there you have it folks. Chef making CFEngine making Puppet making Chef. These tools can be used to automate literally anything, and they're pretty easy to use once you figure out how they work. I was going to throw some Bcfg2 and LCFG in there just for fun, but I only had some much free time =)</p>

<p>Configuration mangement is like a portal.</p>

<p>-s</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CFEngine Puppet and Chef Part 2]]></title>
    <link href="http://someara.github.com/post/2011/12/30/cfengine-puppet-and-chef-part-2/"/>
    <updated>2011-12-30T20:10:00-05:00</updated>
    <id>http://someara.github.com/post/2011/12/30/cfengine-puppet-and-chef-part-2</id>
    <content type="html"><![CDATA[<p>In the previous installment, we used Chef to configure CFEngine to serve policy that allowed us to create a Puppet service. In this one, we'll have Chef use that Puppet service to create a Chef server. If you think this is a ridiculous thing to do, I would be inclined to agree with you. However, this is my blog so I make the rules.</p>

<h2> Puppet </h2>


<p>Puppet at its core works like CFEngine. Statements in Puppet are convergent operators, in that they are declarative (and therefore idempotent), and convergent in that they check a resource's state before taking any action. Like the NTP example from the CFEngine installment, non-optimally ordered execution will usually work itself out after repeated Puppet runs.</p>

<p>Unlike CFEngine, where policy is copied and evaluated on the edges, Puppet clients connect to the Puppet server where configuration is determined based on a certificate CN. A catalog of serialized configuration data is shipped back to the client for execution. This catalog is computed based on the contents of the manifests stored on the server, as well as a collection of <a href=http://puppetlabs.com/puppet/related-projects/facter target="_blank">facts</a> collected from the clients. Puppet facts, like CFEngine hard classes, are discoverable things about a node such as OS version, hostname, kernel version, network information, etc.</p>

<p>{% img left http://images3.wikia.nocookie.net/__cb20050917222913/memoryalpha/en/images/d/d6/Coffee_replicates_then_mug.jpg 300 300 %}</p>

<p>Puppet works a bit like the food replicators in Star Trek. <a href=http://docs.puppetlabs.com/references/stable/type.html target="_blank">Resources</a> make up the basic atoms of a system, and the precise configuration of each must be defined. If a resource is defined twice in a manifest with conflicting states, Puppet refuses to run.</p>

<p>Ordering can be specified though <code>require</code> statements that set up relations between resources. These are used to build a <a href=http://en.wikipedia.org/wiki/Directed_graph target="_blank">directed graph</a>, which Puppet sorts <a href=http://en.wikipedia.org/wiki/Topological_sorting>topologically</a> and uses to determine the final ordering. If a resource in a chain fails for some reason, dependent resources down the graph will be skipped.</p>

<p>This allows for isolation of non-related resources collections. For example, if a package repository for some reason fails to deliver the 'httpd' package, its dependent configuration file and service resources will be skipped. This has nothing to do with an SSH resource collection, so the resources concerning that service will be executed even though the httpd collection had previously failed.</p>

<p>Just be careful not to create the coffee without the cup.</p>

<h2> chef.pp </h2>


<p>Let's examine a Puppet manifest that creates a Chef server on Centos 6.</p>

<p>{% include_code lang:ruby cookbooks/cfengine/files/default/server/puppet/manifests/classes/chef.pp %}</p>

<h2> Picking it apart </h2>


<p>Line 1 is a Puppet class definition. This groups the resource statments between together, allowing us to assign <code>chef-server</code> to a node based on its hostname. This can be accomplished with an explicit nodes.pp definition, or with an external node classifier.</p>

<p>Line 3 is an <code>exec</code> resource, which we can later refer to with its name: <code>rbel6-release</code>. When using <code>exec</code> resources, it's up to you to specify a convergence check. In this case, we used the <code>unless</code> keyword to check the return status of an rpm command. The same goes for <code>command</code> promise types in CFEngine, or an <code>execute</code> resources in Chef.</p>

<p>Line 9 is an example of an array variable, which is iterated over in line 21, much like a CFEngine slist.</p>

<p>Everything else is a standard Puppet resource declaration, each of which have a type, a name, and an argument list. Like CFEngine promises, each type has various intentions available under the hood. Packages can be installed. Services can be running or stopped, and files can be present with certain contents and permissions.</p>

<p>Refer to the Puppet <a href=http://docs.puppetlabs.com/ target="_blank">documentation</a> for more details.</p>

<h2> On to Chef </h2>


<p>{% codeblock lang:sh %}
knife bootstrap centos6-3 -r 'role[affs-chef]' -N "affs-chef-1.example.com" -E development -d affs-omnibus-pre -x root
{% endcodeblock %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CFEngine Puppet and Chef Part 1]]></title>
    <link href="http://someara.github.com/post/2011/12/30/cfengine-puppet-and-chef-part-1/"/>
    <updated>2011-12-30T20:09:00-05:00</updated>
    <id>http://someara.github.com/post/2011/12/30/cfengine-puppet-and-chef-part-1</id>
    <content type="html"><![CDATA[<h2> Introduction </h2>


<p>Over the past few years, the topic of Infrastructure Automation has received a huge amount of attention. The three most commonly used tools for doing this (in order of appearance) are CFEngine, Puppet, and Chef. This article explores each of them by using one to set up another. If you have a chef-server or Hosted Chef account, you can follow along by following the instructions in the setup section. (Full disclosure: I work for Opscode, creators of Chef.)</p>

<h2> Infrastructure </h2>


<p><a href=http://www.infrastructures.org target="_blank">“Infrastructure”</a> turns out to be the hardest thing to explain when discussing automation, yet is the most critical to understand. In this context, Infrastructure isn’t anything physical (or virtualized) like servers or networks. Instead, what we’re talking about is all the “stuff” that is configured across machines to enable an application or service.</p>

<p>In practice, “stuff” translates to operating system baselines, kernel settings, disk mounts, OS user accounts, directories, symlinks, software installations, configuration files, running processes, etc. People of the ITIL persuasion may think of these as Configuration Items. Units of management are composed into larger constructs, and complexity arises as these arrangements become more intricate.</p>

<p>Services running in an Infrastructure need to communicate with each other, and do so via networks. Even when running on a single node, things still communicate over a loopback address or a Unix domain socket. This means that Infrastructure has a topology, which is in itself yet another thing to manage.</p>

<h2> Automation </h2>


<p>{% img left http://upload.wikimedia.org/wikipedia/commons/7/75/Duck_of_Vaucanson.jpg %}</p>

<p>Here is a picture of a duck.</p>

<p>This duck happens to be an <a href=http://en.wikipedia.org/wiki/Automaton target="_blank">automaton</a>. An automaton is a self-operating machine. This one pretends to digest grain. It interacts with its environment by taking input and producing output. To continue operating, the duck requires maintenance. It needs to be wound, cleaned, and repaired. Automated services running on a computer are no different.</p>

<p>Once turned on, an automated service takes input, does something useful, then leaves logs and other data in its wake. Its machinery is the arrangement of software installation, configuration, and the running state of a process. Maintenance is performed in a <a href=http://en.wikipedia.org/wiki/Autonomic_Computing target="_blank">control loop</a>, where an agent comes around at regular intervals inspecting its parts and fixing anything that’s broken.</p>

<p>In automated configuration management, the name of the game is hosting policy. The agents that build and maintain systems pull down blueprints and set to work building our automatons. When systems come back up from maintenance or new ones spring into existence, they configure themselves by downloading policy from the server.</p>

<h2> Setup </h2>


<p>If you'd like to follow along by configuring your own machines with knife, follow the setup instructions <a href=/cfchefipuppetengine-setup target="_blank">here</a>. The setup will get your Chef workstation configured, code checked out from my blog git repo, and uploaded to chef-server for use. Otherwise, you can just browse the source <a href=https://github.com/someara/affs-blog target="_blank">here</a></p>

<h2> CFEngine </h2>


<p>{% img right http://farm1.staticflickr.com/120/293693669_59574a7640_m.jpg A picture of what a cloud may look like %}</p>

<p>CFEngine is a system based on <a href=http://research.iu.hio.no/papers/rosegarden.pdf target="_blank">promise</a> <a href=http://project.iu.hio.no/papers/origin2.pdf target="_blank">theory</a>. Promises are the basic atoms of the CFEngine universe. They have names, types, and intentions (among other things), and each acts as a convergent operator to move its subject toward an intended state. Like the parts in our duck, promises are assembled to create a larger whole.</p>

<p>Promises of various types are capable of different things. Promises of type "package" can interact with a package manager to make sure somthing is installed or removed, while a promise of type "file", can copy, edit, and set permissions. Processes can be started or stopped, and commands can be ran if needed. Read all about them in the CFEngine <a href=http://cfengine.com/manuals/cf3-reference.html target="_blank">reference manual</a>.</p>

<p>Promises provide a <a href=http://c2.com/cgi/wiki?DeclarativeDefinition target="_blank">declarative</a> interface to resources under management, which has the remarkably handy attribute of being <a href=http://en.wikipedia.org/wiki/Idempotence target="_blank">idempotent</a>. An idempotent function gives the same result when applied multiple times. This allows our duck repairing maintence loop (in the form of cf-agent on a cron) to come around and safely execute instructions without having to worry about side effects. Consider "the line 'foo' should exist in the file" vs "append 'foo' to the end of the file"; the non-declarative 'append' would not be safe to repeat.</p>

<p><a href=http://en.wikipedia.org/wiki/Convergence_(mathematics) target="_blank">Convergent</a> maintenance refers to the continuous repair of a system towards a desired state. At the individual promise level, convergence happens in a single run of the maintenance loop. If a package is supposed to be installed but isn't, action will be taken to fix it. If a process is not running but should be, action will be taken again. Convergence in a larger system of promises can take multiple runs if things are processed in a non-optimal order. Consider the following:</p>

<p>{% codeblock %}
Start the NTP service.
Make sure the NTP configuration file is correct, restart the NTP service if repaired.
Install the NTP package.
{% endcodeblock %}</p>

<p>Assuming a system with a base install, the first promise would fail to be kept. The NTP binary is not available, since we haven't installed its package yet. The second promise would write the configuration file, but fail to restart the service. The third promise would succeed, assuming an appropriate package repo was available and functioning properly. After the first run is complete, the system has converged closer to where we want it to be, but isn't quite there yet. Applying the functions again gets us closer to our goal.</p>

<p>The second run of the loop would succeed in starting the service, but would be using the wrong configuration file. The package install from the previous loop clobbered the one written previously. Promise number two would fix the config and restart the service, and the third would do nothing because the package is already installed. Finally, we've converged to our desired system state. A third loop would take no actions at all.</p>

<h2> Kicking things off </h2>


<p>To set up a CFEngine server, invoke the following Chef command:</p>

<p>{% codeblock lang:sh %}
knife bootstrap centos6-1 -r 'role[cfengine]' -N "cfengine-1.example.com" -E development -d affs-omnibus-pre -x root
{% endcodeblock %}</p>

<p>When Chef is done doing its thing, you'll end up with a functioning CFEngine policy host, happily promising to serve policy. Log into the freshly configured machine and check it out. Three things have happened. First, the cfengine package itself has been installed. Second, two directories have been created and populated: <code>/var/cfengine/inputs</code>, and <code>/var/cfengine/masterfiles</code>.</p>

<p>The <code>inputs</code> directory contains configuration for the CFEngine itself, which includes a promise to make the contents of <code>masterfiles</code> available for distribution. When a CFEngine client comes up, it will copy the contents of <code>/var/cfengine/masterfiles</code> from the server into its own <code>inputs</code> directory.</p>

<h2> Examining policy </h2>


<p>CFEngine's main configuration file is <code>promises.cf</code>, from which everything else flows.  Here's a short snippet:</p>

<p>{% codeblock promises.cf snippet lang:ruby %}
body common control
{
  bundlesequence  => {</p>

<pre><code>"update",
"garbage_collection",
"cfengine",
"puppet_server",
</code></pre>

<p>  };</p>

<p>  inputs  => {</p>

<pre><code>"update.cf",
"cfengine_stdlib.cf",
"cfengine.cf",
"garbage_collection.cf",
"puppet.cf",
</code></pre>

<p>  };
}
{% endcodeblock %}</p>

<p>The bundlesequence section tells cf-agent what promise bundles to execute, and in what order. The one we're examining today is named puppet_server, found in <code>puppet.cf</code></p>

<p>{% include_code lang:ruby cookbooks/cfengine/templates/default/inputs/puppet.cf.erb %}</p>

<p>A promise bundle is CFEngine's basic unit of intent. It's a place to logically group related promises. Within a bundle, CFEngine processes things with <a href=http://cfengine.com/manuals/cf3-reference.html#Normal-ordering target="_blank">normal ordering</a>. That is, variables are converged first, then classes, then files, then packages, and so on. I wrote the bundle sections in normal order to make it easier to read, but they could be rearranged and still have the same effect. Without going into too much detail about the language, I'll give a couple hints to help with groking the example.</p>

<p>First, in CFEngine, the word 'class' does not mean what it normally does in other programming languages. Instead, classes are boolean flags that describe context. Classes can be 'hard classes', which are discovered attributes about the environment (hostname, operating system, time, etc), or 'soft classes', which are defined by the programmer. In the above example, puppetmaster_enabled and iptables_enabled are soft classes set based on the return status of a command. In the place of <code>if</code> or <code>case</code> statements, boolean checks on classes are used.</p>

<p>Second, there are no control statements like <code>for</code> or <code>while</code>. Instead, when lists are encountered they are automatically iterated. Check out the packages section for examples of both class decisions and list iteration. Given those two things, you should be able to work your way through the example. However, there's really no getting around reading the reference manual if you want to learn CFEngine.</p>

<h2> On to Puppet </h2>


<p>Finally, let's go ahead and use Chef to bring up a CFEngine client, which will be turned into a Puppet server.</p>

<p>{% codeblock lang:sh %}
knife bootstrap centos6-2 -r 'role[puppet]' -N "puppet-1.example.com" -E development -d affs-omnibus-pre -x root
{% endcodeblock %}</p>

<p>The first run will fail, since the host's IP isn't yet in the cfengine server's allowed hosts lists. Complete the convergence by running these commands:</p>

<p>{% codeblock lang:sh %}
knife ssh "role:cfengine" -a ipaddress chef-client
knife ssh "role:puppet" -a ipaddress chef-client
knife ssh "role:puppet" -a ipaddress chef-client
{% endcodeblock %}</p>

<p>And viola! A working Puppet server, serving policy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Brief Chef Tutorial (from concentrate)]]></title>
    <link href="http://someara.github.com/post/2011/03/16/a-brief-chef-tutorial-from-concentrate/"/>
    <updated>2011-03-16T15:18:00-04:00</updated>
    <id>http://someara.github.com/post/2011/03/16/a-brief-chef-tutorial-from-concentrate</id>
    <content type="html"><![CDATA[<h2> Overview </h2>


<p></p>

<p>Chef is configuration management platform written in Ruby. Configuration management is a large topic that most systems administrators and IT management are just now starting to gain experience with. Historically, infrastructures have been maintained either by hand, with structured scripting, by imagine cloning, or a combination of those. Chef’s usage model rejects the idea of cloning and maintaining “golden images”. Instead, the idea is to start with an embryonic image and grow it into it’s desired state. This works much better as infrastructure complexity increases, and eliminates the problem of image sprawl. The convergent nature of the tool allows you to change the infrastructure over time without much fuss. Chef allows you to express your infrastructure as code, which lets you store it in version control.</p>

<p>“A Can of Condensed Chef Documentation” is available <a href=/post/2011/03/15/a-can-of-condensed-chef-documentation/> here </a></p>

<h2> Prerequisites </h2>




<h3> Git </h3>


<p>Actually you can use any SCM, but git is the most widely adopted in the Chef community. All Chef Git repos begin their lives as clones of the Opscode chef-repo, found here: https://github.com/opscode/chef-repo There is a nice overview of the repo structure (cookbooks, databags, roles, etc) in the README.</p>

<h3> chef-server up and running at a known IP or FQDN. </h3>


<p>This is easily installed from packages by following the instructions on the opscode wiki. The process amounts to “add a package repository, install the packages, and turn it on” Alternatively, you could use the Opscode Platform and go dancing with space robots.</p>

<h3> Knife installed on your local system </h3>


<p>{% codeblock lang:sh %}
gem install chef net-ssh net-ssh-multi fog highline
{% endcodeblock %}</p>

<h3> Chef git repo checked out on local file system </h3>


<p>{% codeblock lang:sh %}
git clone https://github.com/opscode/chef-repo
{% endcodeblock %}</p>

<h3> Client certificate creation </h3>


<p>A “client” in chef parlance is an SSL certificate used to access the chef-server API. If the client’s CN name is marked “admin” in chef-server, the client can perform restricted operations such as creating and deleting nodes. This is the kind of client needed by knife to manipulate the infrastructure, and normally correspond to actual human being, but by no means has to. Nodes have non-admin client certificates, and can only manipulate their own node objects. To create a client certificate, you’ll need to log into the chef-server webui, click on “clients”, think of a name for it (I use someara), and paste the displayed private key into a local file.</p>

<p><strong> Copy the validation key </strong><br>
The validation key is a special key that is shared by all freshly bootstrapped nodes. It has the ability to create new client certificates and nodes objects through the API.</p>

<p>{% codeblock lang:sh %}
scp root@chefserver:/etc/chef/validation.pem .chef/
{% endcodeblock %}</p>

<h3> Edit configuration files </h3>


<p>For more details on this section, please visit http://wiki.opscode.com/display/chef/Chef+Configuration+Settings</p>

<p>.chef/client.rb - This file is copied onto the nodes that are bootstrapped with knife, and needs to be configured to point to the IP or FQDN of your chef server</p>

<p>example
{% codeblock $ vim client.rb %}
log_level          :info
log_location       STDOUT
ssl_verify_mode    :verify_none
chef_server_url    "http://y.t.b.d:4000"
file_cache_path    "/var/cache/chef"
pid_file           "/var/run/chef/client.pid"
cache_options({ :path => "/var/cache/chef/checksums", :skip_expires => true})
signing_ca_user "chef"
Mixlib::Log::Formatter.show_time = true
validation_client_name "chef-validator"
validation_key         "/etc/chef/validation.pem"
client_key             "/etc/chef/client.pem"
{% endcodeblock %}</p>

<p>.chef/knife.rb - This file also needs to be configured to point to your chef-server, and also to the client private key that was created earlier.</p>

<p>example
{% codeblock $ vim knife.rb %}
log_level            :info
log_location         STDOUT
node_name           'knife'
cache_type          'BasicFile'
cache_options( :path => "~/.chef/checksums" )
client_key       '~/.chef/knife.key.pem'</p>

<p>cookbook_path       [ "~/mychefrepo/cookbooks" ]
cookbook_copyright "example org"
cookbook_email     "cookbooks@example.net"
cookbook_license   "apachev2"</p>

<p>chef_server_url    "http://y.t.b.d:4000"</p>

<p>validation_key      "~/.chef/validation.pem"</p>

<h1>rackspacecloud</h1>

<p>knife[:rackspace_api_key] = '00000000000000000000000000000000'
knife[:rackspace_username] = 'rackspace'</p>

<h1>slicehost</h1>

<p>knife[:slicehost_password] = '0000000000000000000000000000000000000000000000000000000000000000'</p>

<h1>AFFS aws</h1>

<p>knife[:aws_access_key_id]     = '00000000000000000000'
knife[:aws_secret_access_key] = '0000000000000000000000000000000000000000'</p>

<h1>knife[:region]  = "us-east-1"</h1>

<h1>knife[:availability_zone] = "us-west-1b"</h1>

<h1>knife[:ssh_user] = "root"</h1>

<h1>knife[:flavor] = "t1.micro"</h1>

<h1>knife[:image] = "ami-10a55279"</h1>

<h1>knife[:use_sudo]  = "false"</h1>

<h1>knife[:distro] = "affs-fc13"</h1>

<p>{% endcodeblock %}</p>

<h2> Role, recipes, and run lists</h2>


<p>As mentioned earlier, run lists are made up from role trees. Here is an example of how you would create a demo server with a correct clock, managed users, and metrics and monitoring capabilities. In this example, six recipes are executed per run, and an unknown number of resources are managed. (To figure that out, you’d have to read the recipes)</p>

<p>{% codeblock %}
role[demo]
  role[base]                   &lt;---- nested role
  recipe[foo::server]
  recipe[foo::muninplugin]</p>

<p>role[base]
  recipe[ntp]
  recipe[localusers::common]
  recipe[munin::client]
  recipe[nagios::client]</p>

<p>expanded run list
  recipe[ntp]</p>

<pre><code>recipe[localusers::common]
recipe[munin::client]
recipe[nagios::client]
recipe[foo::server]
recipe[foo::muninplugin]
</code></pre>

<p>{% endcodeblock %}</p>

<p>That’s quite a bit of cooking for a beginner tutorial, so we’re just going to focus on a single node running an NTP client for now. Roles can be written either as .rb files or .json files. I prefer to use the .rb format because they’re easier to read and write. Some people prefer to deal with the JSON formatted version directly, since thats the way they’re dumped with knife. At the end of the day, it doesn’t really matter, so do which ever makes you happy.</p>

<h3> Step One : Creating a demo role file </h3>


<p>{% codeblock $ vim roles/demo.rb %}
name "demo"
description "demo role"
run_list [</p>

<pre><code>"recipe[ntp]"
]
</code></pre>

<p>{% endcodeblock %}</p>

<h3> Step Two : Installing the role on chef-server </h3>


<p>{% codeblock lang:sh %}
$ knife role from file roles/demo.rb
{% endcodeblock %}</p>

<h2> Writing Recipes </h2>


<h3> Hello, NTP! </h3>


<p>A machine’s NTP client is simple to install and configure. Every systems administrator is already familiar with it, which makes it a great example.</p>

<p>Most software available as a native package in a given linux distribution can be managed with a “package, template, service” design pattern.</p>

<p>Each of those words refers to a Chef resource, which we pass arguments to.</p>

<h3> Step One : Creating an ntp cookbook </h3>


<p>{% codeblock lang:sh %}
$ knife cookbook create ntp
{% endcodeblock %}
This creates a directory structure for the ntp cookbook. You can check it out with ls:
{% codeblock lang:sh %}
$ ls -la cookbooks/ntp/
total 24
drwxr-xr-x  13 someara  staff   442 Mar 14 17:56 .
drwxr-xr-x  36 someara  staff  1224 Mar 15 19:39 ..
-rw-r--r--   1 someara  staff    58 Mar 14 17:56 README.rdoc
drwxr-xr-x   2 someara  staff    68 Mar 14 17:56 attributes
drwxr-xr-x   2 someara  staff    68 Mar 14 17:56 definitions
drwxr-xr-x   3 someara  staff   102 Mar 14 17:56 files
drwxr-xr-x   2 someara  staff    68 Mar 14 17:56 libraries
-rw-r--r--   1 someara  staff   259 Mar 14 17:56 metadata.rb
drwxr-xr-x   2 someara  staff    68 Mar 14 17:56 providers
drwxr-xr-x   4 someara  staff   136 Mar 14 17:56 recipes
drwxr-xr-x   2 someara  staff    68 Mar 14 17:56 resources
drwxr-xr-x   3 someara  staff   102 Mar 14 17:56 templates
{% endcodeblock %}</p>

<h3> Step Two : Deciding what to name the recipe </h3>


<p>Recipe names are related to cookbook structure. Putting recipe[foo::bar] in a node’s run list results in cookbooks/foo/recipes/bar.rb being downloaded from chef-server and executed.</p>

<p>There is a special recipe in every cookbook called default.rb. It is executed by every recipe in the cookbook. Specifying recipe[foo::bar] actually results in cookbooks/foo/recipes/default.rb, as well as cookbooks/foo/recipes/bar.rb being executed.</p>

<p>Default.rb is a good place to put common stuff when writing cookbooks with multiple recipes, but we’re going to keep it simple and just use default.rb for everything.</p>

<h3> Step Three : Creating a recipe </h3>


<p>This is where all the fun stuff happens. When using resources, you’re writing things in a declarative fashion. Declarative means you can concentrate on the WHAT without having to worry about the HOW. Chef will take care of that for you with something called a resource provider. When installing a package, it will check to see what your operating system is and use the appropriate methodology. For example, on Debian based systems, it will use apt-get, and on Redhat based systems, it will use yum.</p>

<p>{% codeblock $ vim cookbooks/ntp/recipes/default.rb %}
package "ntp" do
  action [:install]
end</p>

<p>template "/etc/ntp.conf" do
  source "ntp.conf.erb"
  variables( :ntp_server => "time.nist.gov" )
end</p>

<p>service "ntpd" do
  action[:enable,:start]
end
{% endcodeblock %}</p>

<p>Chef recipes are evaluated top down (like a normal ruby program), with each resource being ran in the order it appears. Order is important. In the above example, if we were to reverse the order of those three resources, it would first fail to start the service (as the software is not installed yet), then write the configuration file, then finally clobber the file it just wrote by installing the package.</p>

<h3> Step Four : Creating the ntp.conf.erb template </h3>


<p>{% codeblock $ vim cookbooks/ntp/templates/default/ntp.conf.erb %}</p>

<h1>generated by Chef.</h1>

<p>restrict default kod nomodify notrap nopeer noquery
restrict -6 default kod nomodify notrap nopeer noquery
restrict 127.0.0.1
restrict -6 ::1
server &lt;%= @ntp_server %>
server  127.127.1.0     # local clock
driftfile /var/lib/ntp/drift
keys /etc/ntp/keys
{% endcodeblock %}</p>

<h3> Step Five : uploading the cookbook to chef-server </h3>


<p>{% codeblock lang:sh %}
$ knife cookbook upload ntp
{% endcodeblock %}</p>

<h2> Bootstraping nodes </h2>


<p>The chef-client needs to somehow get itself installed and running on managed nodes. This process is known as bootstrapping and is accomplished with shell scripting. The method of bootstrap will vary depending on how you go about provisioning your server, and the script will depend on the platform.</p>

<h3> Clouds </h3>


<p>Cloud providers like AWS and Rackspace will let you make an API request, then return the IP of your compute resource.</p>

<p>{% codeblock lang:sh %}
$ knife ec2 server create "role[demo]" -N "demo.example.net" -i ami-3e02f257
{% endcodeblock %}</p>

<p>In this example, knife uses the ruby fog library to talk to ec2 and request a server with an argument of the desired AMI. Knife then uses net-ssh-multi to ssh into the machine and execute a bootstrapping script. There are a number of other arguments that can be passed to knife, such as ec2 region, machine size, what ssh key to use. You can read all about them on the Opscode wiki.</p>

<h3> Meatclouds </h3>


<p>If your method of provisioning servers is “ask your VMware administrator” or “fill out these forms”, then you’ll probably bootstrap via an IP address.</p>

<p>{% codeblock lang:sh %}
knife boostrap 10.0.0.5 -x root -N demo.example.net -r 'role[demo]' -d pp-centos5
{% endcodeblock %}</p>

<h3> Cobbler / FAI / pxe_dust / Jumpstart / etc </h3>


<p>In these provisioning scenarios, you can skip knife completely and put the contents of a bootstrap script kickstart or equivalent.</p>

<h2> Customizing the bootstrap </h2>


<p>By default (with no arguments), Chef attempts a gem based installation meant to work on Ubuntu. If you’re not using Ubuntu, or are uncomfortable installing gems directly from rubygems.org, you’ll have to change the script to suite your taste. It works by specifying a template name with the -d flag, SSH’ing into the machine and running the rendered script. When using knife to SSH, make sure you have the correct key loaded into your ssh-agent.</p>

<h3> Example </h3>


<p>{% codeblock lang:sh %}
knife boostrap 10.0.0.5 -x root -N demo.example.net -r ‘role[demo]’ -d my-centos5
{% endcodeblock %}
ends up running this</p>

<p>{% codeblock lang:sh %}
ssh root@10.0.0.179 bash -c ‘<contents of rendered .chef/bootstrap/my-centos5.erb template>’
{% endcodeblock %}</p>

<p>What I do in my boot scripts:</p>

<ul>
<li>Correctly set the hostname to value of -N argument. (By correctly, I mean that <code>hostname -f</code> has to work properly)</li>
<li>Configure the package repositories</li>
<li>Install Chef. I like packages using the native package manager</li>
<li>Copy the validation key</li>
<li>Write /etc/chef/client.rb (points to server)</li>
<li>Write a json file with the contents of the -r argument</li>
<li>chef-client -j bootstrap.json</li>
</ul>


<p>After the script is ran, chef-client does the following</p>

<ul>
<li>Ohai!</li>
<li>Client registration: SSL CN is FQDN from ohai</li>
<li>Node creation: Node name is also FQDN from ohai, run lists are from JSON</li>
<li>Expands run list</li>
<li>Downloads needed cookbooks</li>
<li>Starts executing recipes</li>
</ul>


<p>There is an example of a custom bootstrap script <a href=https://github.com/someara/affs-blog/blob/v1/.chef/bootstrap/affs-fc13.erb> here </a></p>

<p>At this point, you should have an ntp client installed, configured, and running.</p>

<p>(It’s actually a little bit more complicated than that. For more information about chef-client runs, see <a href=http://wiki.opscode.com/display/chef/Anatomy+of+a+Chef+Run> http://wiki.opscode.com/display/chef/Anatomy+of+a+Chef+Run </a>)</p>

<h2> Databag Driven Recipes </h2>


<p>Data driven infrastructures are all the rage these days. This allows you to do things like change the NTP server all your nodes use by editing a single JSON value in chef-server. You can get really creative with this, so let your imagination run wild.</p>

<h3> Step One : Create an ntp data bag </h3>


<p>{% codeblock lang:sh %}
$ knife data bag create ntp
$ mkdir -p data_bags/ntp
$ vim data_bags/ntp/default_server.json
{</p>

<pre><code>"id" : "default_server",
  "value" : "us.pool.ntp.org"
</code></pre>

<p>}
{% endcodeblock %}</p>

<h3> Step Two : Upload data bag to chef-server </h3>


<p>{% codeblock lang:sh %}
$ knife data bag from file ntp data_bags/ntp/default_server.json
{% endcodeblock %}</p>

<h3> Step Three : Modify the recipe to take advantage of it </h3>


<p>{% codeblock ntp/recipes/default.rb %}
package "ntp" do
  action [:install]
end</p>

<p>ntp_server = data_bag_item('ntp', 'default_server')</p>

<p>template "/etc/ntp.conf" do
  source "ntp.conf.erb"
  variables( :ntp_server => ntp_server['value'] )
end</p>

<p>service "ntpd" do
  action[:enable,:start]
end
{% endcodeblock %}</p>

<p>You can also access data bag data through the search() interface, which you can read about on the opscode wiki.</p>

<h3>Step Four : uploading the cookbook to chef-server</h3>


<p>{% codeblock lang:sh %}
$ knife cookbook upload ntp
{% endcodeblock %}</p>

<h2> Understanding Idempotence and Convergence </h2>


<p>We’re not quite done yet. Let’s SSH into our shiny new NTP enabled machine and go poking about.</p>

<p>{% codeblock lang:sh %}
$ grep server /etc/ntp.conf | head -n 1
server time.nist.gov
{% endcodeblock %}</p>

<p>Wait a sec, isn’t that supposed to be “us.pool.ntp.org”? Not yet. We haven’t enabled our convergence mechanism yet! If we manually run chef-client on the node, we will indeed see that the file has changed.</p>

<h3> Convergence </h3>


<p>{% codeblock lang:sh %}</p>

<h1>chef-client</h1>

<p>$ grep server /etc/ntp.conf | head -n 1
us.pool.ntp.org
{% endcodeblock %}</p>

<p>That file just converged into the correct state. Lets edit the file again, this time filling it with complete garbage.</p>

<p>{% codeblock lang:sh %}</p>

<h1>dd if=/dev/urandom of=/etc/ntp.conf bs=128 count=1</h1>

<h1>chef-client</h1>

<p>$ grep server /etc/ntp.conf | head -n 1
us.pool.ntp.org
{% endcodeblock %}</p>

<p>Again, the file converged into the correct state. Awesome. Running chef-client by hand on a large cluster of nodes would be a real pain, so it makes sense to set it up automatically. Indeed, often found in a “role[base]” is a “recipe[chef-client]” that configures it to run as a daemon, or from a cron.</p>

<h3> Idempotence </h3>


<p>It is safe to run the recipes on the nodes time and time again because resources are written to be idempotent. You may remember from math class that a function f is idempotent if, for all values of x, f(f(x))=f(x). That means you can run a function over a resource a bajillion times and it will behave as if it was only done once.</p>

<p>This is implemented under the hood as “If it ain’t broke, don’t fix it.” In a file resource, checksums are calculated and compared. In a package resource, the rpm or dpkg databases are consulted to see if the package is installed. The effect of this is that most chef-client runs do absolutely nothing to resources. That is, until you change the function by altering the inputs to the resource providers.</p>

<h2> Notifications and Subscriptions </h2>


<p>Further examination reveals that the ntpd service is still talking to “time.nist.gov”. This is because during the chef-client run, the resource named “ntpd” ran it’s idempotency check, and found that it was, in fact, running. It therefore did nothing. It we want ntpd to restart when the contents /etc/ntp.conf are altered, we have to modify our recipe to set up that relation.</p>

<p>{% codeblock ntp/recipes/default.rb %}
package "ntp" do
  action [:install]
end</p>

<p>ntp_server = data_bag_item('ntp', 'default_server')</p>

<p>template "/etc/ntp.conf" do
  source "ntp.conf.erb"
  variables( :ntp_server => ntp_server['value'] )
  notifies :restart, "service[ntpd]"
end</p>

<p>service "ntpd" do
  action[:enable,:start]
end
{% endcodeblock %}</p>

<p>Alternatively, we could have set up the “service[ntpd]” resource to subscribe to the “template[/etc/ntp.conf]” resource.</p>

<p>Upload the modified ntp cookbook to chef-server and re-run the client on your demo server to check your work.
{% codeblock lang:sh %}</p>

<h1>chef-client</h1>

<p>$ lsof -i | grep ntp | grep pool
ntpd       5673    ntp   19u  IPv4 12481380      0t0  UDP us.pool.ntp.org:ntp}
{% endcodeblock %}
Winning.</p>

<h2> Bulk Loading data into chef-server </h2>


<p>To save yourself from writing crazy for loops on command line like</p>

<p>{% codeblock lang:sh %}
for i in <code>ls cookbooks</code> ; do knife cookbook upload $i ; done
{% endcodeblock %}</p>

<p>Or even worse,</p>

<p>{% codeblock lang:sh %}
for i in <code>ls data_bags</code> ; do
  for j in <code>ls data_bags/$i/</code>; do</p>

<pre><code>knife data bag create $i
knife data bag from file $i data_bags/$i/$j ;
</code></pre>

<p>  done ;
done
{% endcodeblock %}</p>

<p>... somebody was nice enough to write some rake tasks. List them with rake -T, and then install your repo in chef-server with "rake install"</p>

<h2> Viewing your Infrastructure </h2>


<p>There are two ways to view your infrastructure. The first is through the management console, and the other is from knife. Here is a list of handy commands to get you started.</p>

<p>{% codeblock lang:sh %}
knife node list
knife node show foo.example.net
knife data bag list
knife data bag show whatever
{% endcodeblock %}</p>

<h2> Deleting Clients, Nodes, and Machines </h2>


<p>Remember that nodes, their client certificates, and the machines they’re associated with are three separate entities.</p>

<h3> Nodes </h3>


<p>{% codeblock lang:sh %}
$ knife node delete foo.example.net
{% endcodeblock %}</p>

<p>This just deletes the node object from chef-server. The next time the machine runs chef-client, the node object will be recreated in chef-server. This node object will have an empty run list what will have to be repopulated before chef-client actually does anything.</p>

<h3> Clients </h3>


<p>{% codeblock lang:sh %}
$ knife client delete foo.example.net
{% endcodeblock %}</p>

<p>This deletes a node object’s associated public key from chef-server. The next time the machine runs chef-client, it will get a permission denied error. If this is done on accident, ssh into the machine, delete it’s client key at /etc/chef/client.pem and re-run chef-client.</p>

<h3> Machines </h3>


<p>Deleting a machine will be specific to how it was provisioned. On AWS, it would look like “knife ec2 server delete i-DEAFBEEF”. On a VMware cluster, it could be by clicking buttons in a GUI. I once deleted a hardware machine by throwing it off a balcony. YMMV.</p>

<h2> nodes.sh </h2>


<p>I like to keep a special directory called “infrastructures” that contain sub-directories and nodes.sh files. A nodes.sh contains a list of knife commands that can be thought of as the highest level view of the infrastructure. for example:</p>

<p>{% codeblock lang:sh %}
knife bootstrap 10.0.0.10 -r 'role[database]'  -N database-01.example.net -x root -d my-fedora13
knife bootstrap 10.0.0.11 -r 'role[database]' -N database-02.example.net -x root -d my-fedora13
knife bootstrap 10.0.0.14 -r 'role[redis]' -N redis01.example.net -x root -d my-fedora13
knife bootstrap 10.0.0.15 -r 'role[redis]' -N redis02.example.net -x root -d my-fedora13
knife bootstrap 10.0.0.14 -r 'role[files]' -N files01.example.net -x root -d my-fedora13
knife bootstrap 10.0.0.15 -r 'role[files]' -N files02.example.net -x root -d my-fedora13
knife bootstrap 10.0.0.16 -r 'role[appdemo]' -N appdemo01.example.net -x root -d my-fedora13
knife bootstrap 10.0.0.17 -r 'role[appdemo]' -N appdemo02.example.net -x root -d my-fedora13
{% endcodeblock %}</p>

<p>This file can eventually be used to bring up entire infrastructures, but during development, lines are typically pasted into a terminal individually.</p>

<p>This is as close as I’ve gotten to replacing myself with a very small shell script so far. Many a sysadmin has been pursuing this for a long time now. It is here. The journey has just begun.</p>

<p>-s</p>
]]></content>
  </entry>
  
</feed>
